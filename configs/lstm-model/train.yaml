#Args
model_name: lstm_model
dir: ./results/lstm-model
model:
  vocab_size: null
  embedding_dim: 300
  hidden_size: 300
  lstm_num_layers: 2
  bidirectional: true
  dropout: 0.4
  num_labels: 3
  
args:
  output_dir: ${dir}/ckpts
  logging_dir: ${dir}/runs
  evaluation_strategy: steps
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  weight_decay: 0.01
  learning_rate: 1e-3
  num_train_epochs: 15
  adam_epsilon: 1e-6
  lr_scheduler_type: cosine_with_restarts
  logging_first_step: true
  warmup_ratio: 0.0
  logging_steps: 20
  save_steps: 100
  eval_steps: 20
  seed: 42
  dataloader_num_workers: 2

trainer:
  save_model_name: ${dir}/lstm-model-final
misc:
  squad_v2: false
  raw_predictions_file: ${dir}/preds/raw
  acc_metric_file: ${dir}/preds/acc.txt
  f1_metric_file: ${dir}/preds/f1.txt
  final_predictions_file: ${dir}/preds/final
